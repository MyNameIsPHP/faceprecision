{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAWnrkiEu-4S",
        "outputId": "376253f9-793e-436c-8eff-040ebb67211b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Connect to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZDGilOP3O9D",
        "outputId": "815ad4fc-76d4-4c38-c91d-d103713053f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tf2onnx in /usr/local/lib/python3.10/dist-packages (1.16.1)\n",
            "Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.23.5)\n",
            "Requirement already satisfied: onnx>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.16.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (23.5.26)\n",
            "Requirement already satisfied: protobuf~=3.20 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (3.20.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2023.11.17)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/dist-packages (1.16.3)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.5.26)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Requirement already satisfied: gdown==4.6.0 in /usr/local/lib/python3.10/dist-packages (4.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown==4.6.0) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown==4.6.0) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown==4.6.0) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown==4.6.0) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown==4.6.0) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown==4.6.0) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.6.0) (2023.11.17)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.6.0) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U tf2onnx\n",
        "!pip install onnxruntime\n",
        "!pip install gdown==4.6.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCL_9D5ivgnc"
      },
      "source": [
        "convert"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download public test\n",
        "!gdown https://drive.google.com/uc?id=<dataset_id>&export=download\n",
        "# Unzip dataset\n",
        "!unzip -qq cropped_faces_private_test.zip\n",
        "# !rm public_test_cropped_faces.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4gDQbq4Hp5w",
        "outputId": "d3da809c-bc9e-492a-fa04-d7071f2a8967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=<datase_id>\n",
            "To: /content/cropped_faces_private_test.zip\n",
            "100% 323M/323M [00:01<00:00, 224MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_cv\n",
        "!pip install deepface\n",
        "\n",
        "import numpy as np\n",
        "import glob\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import time\n",
        "\n",
        "import os\n",
        "import gdown\n",
        "import tensorflow as tf\n",
        "from deepface.commons import functions\n",
        "from deepface.commons.logger import Logger\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout\n",
        "\n",
        "# ---------------------------------------\n",
        "\n",
        "tf_version = int(tf.__version__.split(\".\", maxsplit=1)[0])\n",
        "\n",
        "if tf_version == 1:\n",
        "    from keras.models import Model, Sequential\n",
        "    from keras.layers import (\n",
        "        Convolution2D,\n",
        "        ZeroPadding2D,\n",
        "        MaxPooling2D,\n",
        "        Flatten,\n",
        "        Dropout,\n",
        "        Activation,\n",
        "        Lambda,\n",
        "    )\n",
        "    from keras import backend as K\n",
        "else:\n",
        "    from tensorflow.keras.models import Model, Sequential\n",
        "    from tensorflow.keras.layers import (\n",
        "        Convolution2D,\n",
        "        ZeroPadding2D,\n",
        "        MaxPooling2D,\n",
        "        Flatten,\n",
        "        Dropout,\n",
        "        Activation,\n",
        "        Lambda,\n",
        "    )\n",
        "    from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "79vH0kVa6Y4n",
        "outputId": "de8c5c85-841f-40bc-b678-aeb031af3bb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_cv\n",
            "  Downloading keras_cv-0.8.1-py3-none-any.whl (606 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m606.4/606.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_cv) (23.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras_cv) (1.4.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras_cv) (2023.6.3)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from keras_cv) (4.9.4)\n",
            "Collecting keras-core (from keras_cv)\n",
            "  Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras_cv) (0.1.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras_cv) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras_cv) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (1.23.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (13.7.0)\n",
            "Collecting namex (from keras-core->keras_cv)\n",
            "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (3.9.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (0.1.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (8.1.7)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (1.6.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (3.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (5.9.5)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (1.14.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (2.4.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (0.10.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (1.14.1)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (0.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (6.1.1)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (4.5.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_cv) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_cv) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_cv) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_cv) (2023.11.17)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from promise->tensorflow-datasets->keras_cv) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras_cv) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras_cv) (2.16.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets->keras_cv) (1.62.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras_cv) (0.1.2)\n",
            "Installing collected packages: namex, keras-core, keras_cv\n",
            "Successfully installed keras-core-0.1.7 keras_cv-0.8.1 namex-0.0.7\n",
            "Collecting deepface\n",
            "  Downloading deepface-0.0.81-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.10/dist-packages (from deepface) (1.5.3)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.6.0)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.66.1)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (9.4.0)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.8.0.76)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.15.0)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.15.0)\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.2.5)\n",
            "Collecting mtcnn>=0.1.0 (from deepface)\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting retina-face>=0.0.1 (from deepface)\n",
            "  Downloading retina_face-0.0.13-py3-none-any.whl (16 kB)\n",
            "Collecting fire>=0.4.0 (from deepface)\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gunicorn>=20.1.0 (from deepface)\n",
            "  Downloading gunicorn-21.2.0-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Deprecated>=1.2.13 (from deepface)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated>=1.2.13->deepface) (1.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire>=0.4.0->deepface) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.4.0->deepface) (2.4.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (3.0.1)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (4.11.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gunicorn>=20.1.0->deepface) (23.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2023.3.post1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (4.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.42.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=1.1.2->deepface) (2.1.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (3.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (0.7.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (2023.11.17)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (3.2.2)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116934 sha256=acbabf50e66dccc2ecd3c7d3b730643be45a270f059871723563eccc10102fd1\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "Successfully built fire\n",
            "Installing collected packages: gunicorn, fire, Deprecated, mtcnn, retina-face, deepface\n",
            "Successfully installed Deprecated-1.2.14 deepface-0.0.81 fire-0.5.0 gunicorn-21.2.0 mtcnn-0.1.1 retina-face-0.0.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wvDXVSL_qi-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resize and segment"
      ],
      "metadata": {
        "id": "_Kprx9H_6nXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/WillBrennan/SemanticSegmentation.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mqv_MrNv4NTD",
        "outputId": "9013c099-81e4-45ca-f633-c1c5ac7c9f16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SemanticSegmentation'...\n",
            "remote: Enumerating objects: 88, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 88 (delta 18), reused 15 (delta 13), pack-reused 49\u001b[K\n",
            "Receiving objects: 100% (88/88), 2.77 MiB | 24.01 MiB/s, done.\n",
            "Resolving deltas: 100% (28/28), done.\n",
            "Filtering content: 100% (4/4), 640.60 MiB | 40.08 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-ignite"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oizO7GE4jmx",
        "outputId": "da75a262-29c5-45c2-cacc-44ccdfa97039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.13-py3-none-any.whl (272 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.4/272.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch<3,>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-ignite) (2.1.0+cu121)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytorch-ignite) (23.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3,>=1.3->pytorch-ignite) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3,>=1.3->pytorch-ignite) (1.3.0)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import shutil\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "def resize_image(img_path, output_path, size=(224, 224)):\n",
        "    img = Image.open(img_path)\n",
        "    img = img.resize(size, Image.LANCZOS)\n",
        "    img.save(output_path)\n",
        "\n",
        "def resize_images_in_folder(folder, output_folder, size=(224, 224), max_workers=5):\n",
        "    # Create the output folder if it does not exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Resize images in the folder using ThreadPoolExecutor\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        for filename in os.listdir(folder):\n",
        "            if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                img_path = os.path.join(folder, filename)\n",
        "                output_path = os.path.join(output_folder, filename)\n",
        "                executor.submit(resize_image, img_path, output_path, size)"
      ],
      "metadata": {
        "id": "Z4HPc9_E6qt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resize_images_in_folder('/content/cropped_faces_private_test', '/content/cropped_faces_private_test_224x224')"
      ],
      "metadata": {
        "id": "IbcUyKyi7c4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=<dataset_id>&export=download\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXpVK6oIii9w",
        "outputId": "8cc14545-d19a-45b6-d548-9757b423eb32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=<dataset_id>\n",
            "To: /content/evaluate_images.py\n",
            "\r  0% 0.00/4.72k [00:00<?, ?B/s]\r100% 4.72k/4.72k [00:00<00:00, 16.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write segmented images here\n",
        "\n",
        "PATH = '/content/SemanticSegmentation/segmented_private_test'\n",
        "if not os.path.exists(PATH):\n",
        "        os.makedirs(PATH)\n",
        "%cd {PATH}\n",
        "# Please remember to  --save-mask-only\n",
        "!python /content/SemanticSegmentation/evaluate_images.py \\\n",
        "--images /content/cropped_faces_private_test_224x224 \\\n",
        "--model /content/SemanticSegmentation/pretrained/model_segmentation_skin_30.pth \\\n",
        "--model-type FCNResNet101 \\\n",
        "--output-folder /content/cropped_faces_private_test_224x224_skin_segmentation \\\n",
        "--save \\\n",
        "--save-mask-only\n"
      ],
      "metadata": {
        "id": "lqoP5YM54TI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ZIP file if you want to use later\n",
        "folder_path = \"/content/cropped_faces_private_test_224x224_skin_segmentation\"\n",
        "zip_name = \"cropped_faces_private_test_224x224_skin_segmentation.zip\"\n",
        "!zip -r {zip_name} {folder_path}\n",
        "\n",
        "!cp \"/content/SemanticSegmentation/segmented_private_test/cropped_faces_private_test_224x224_skin_segmentation.zip\" \"/content/gdrive/MyDrive/Skintone_Classification\""
      ],
      "metadata": {
        "id": "9it4-rsYHCRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "8EW0npfnlhNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image_facenet(image_path):\n",
        "    image_size = (160, 160)\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Check if the image is loaded properly\n",
        "    if image is None:\n",
        "        print(f\"Failed to load image: {image_path}\")\n",
        "        return None\n",
        "\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, image_size)\n",
        "    image = image / 255.0\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    return image.astype(np.float32)\n",
        "\n",
        "def create_feature_vector(image):\n",
        "    # Assuming grayscale images, calculate histogram for the single channel, excluding zeros\n",
        "    hist, _ = np.histogram(image[image != 0], bins=256, range=(1, 255))\n",
        "\n",
        "    # Normalize the histogram into a single feature vector\n",
        "    sum_of_vector = hist.sum()\n",
        "\n",
        "    if sum_of_vector != 0:\n",
        "        feature_vector = hist / sum_of_vector\n",
        "    else:\n",
        "        feature_vector = np.zeros_like(hist)\n",
        "\n",
        "    # Convert feature vector to float32 and reshape to 2D\n",
        "    feature_vector = feature_vector.astype(np.float32).reshape(1, -1)\n",
        "\n",
        "    return feature_vector\n",
        "\n",
        "\n",
        "\n",
        "def predict_skintone(image_path):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"Failed to load image: {image_path}\")\n",
        "        return \"Unknown\"\n",
        "\n",
        "    # Convert to grayscale\n",
        "    grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    print(f\"Grayscale Image Shape: {grayscale_image.shape}\")\n",
        "\n",
        "    # Create feature vector from the grayscale image\n",
        "    feature_vector_input = create_feature_vector(grayscale_image)\n",
        "    print(f\"Feature vector shape: {feature_vector_input.shape}, Sample: {feature_vector_input[0][:5]}\")\n",
        "\n",
        "    # Predict skintone using the model\n",
        "    skintone_output = skintone_session.run(None, {'dense_input': feature_vector_input})\n",
        "    print(f\"Raw model output: {skintone_output}\")\n",
        "\n",
        "\n",
        "    return skintone_output"
      ],
      "metadata": {
        "id": "PX9ZL5UqljVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=<dataset_id>&export=download\n",
        "!gdown https://drive.google.com/uc?id=<dataset_id>&export=download\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ze1xyHpqBnx",
        "outputId": "c4322948-b65e-4c8b-fc84-7ebb2d843ea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=<dataset_id>\n",
            "To: /content/SemanticSegmentation/segmented_private_test/model_race_ptFaceNet_lr0.001_bs64_cw_oversampling_augmented_largerDataset.onnx\n",
            "100% 96.1M/96.1M [00:00<00:00, 170MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import onnxruntime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "folder_path = '/content/cropped_faces_private_test'\n",
        "answer_path = '/content/answer_private_test.xlsx'\n",
        "filename_prefix = 'mask_skin_'\n",
        "\n",
        "# Load DataFrame from Excel\n",
        "df = pd.read_excel(answer_path)\n",
        "\n",
        "prediction_mapping = {0: 'Caucasian', 1: 'Mongoloid', 2: 'Negroid'}\n",
        "skintone_mapping = {0: 'dark', 1: 'light', 2: 'mid-dark', 3: 'mid-light' }\n",
        "\n",
        "# Load the skintone prediction ONNX model\n",
        "skintone_model_path = '/content/model_skintone_histogram_preprocess_image_IQR25_75th.onnx'\n",
        "skintone_session = onnxruntime.InferenceSession(skintone_model_path)\n",
        "\n",
        "# Load the facenet model\n",
        "facenet_session = onnxruntime.InferenceSession('/content/model_race_ptFaceNet_lr0.001_bs64_cw_oversampling_augmented_largerDataset.onnx')\n",
        "completed_images=0\n",
        "total_images = len(df)\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    image_file = row['image_file']\n",
        "    image_path = os.path.join(folder_path, image_file)\n",
        "    print(image_path)\n",
        "\n",
        "    # Preprocess the image for facenet\n",
        "    input_data_facenet = preprocess_image_facenet(image_path)\n",
        "\n",
        "    # Run inference with facenet\n",
        "    output_facenet = facenet_session.run(None, {'input_5': input_data_facenet})[0]\n",
        "\n",
        "\n",
        "    # Combine predictions based on weights\n",
        "    prediction_race = np.argmax(output_facenet, axis=1)[0]\n",
        "    prediction_race_label = prediction_mapping.get(prediction_race, 'Unknown')\n",
        "\n",
        "    # Update DataFrame with prediction\n",
        "    df.at[index, 'race'] = prediction_race_label\n",
        "\n",
        "\n",
        "    # SKINTONE\n",
        "    image_file = filename_prefix + row['image_file']  # Add the prefix here\n",
        "    image_path = os.path.join('/content/cropped_faces_private_test_224x224_skin_segmentation', image_file)\n",
        "\n",
        "    output_skintone = predict_skintone(image_path)\n",
        "\n",
        "    if prediction_race_label == 'Negroid':\n",
        "              # Create a new list with modified values\n",
        "              output_skintone[0][0][0]*=0.4739\n",
        "              output_skintone[0][0][1]*=0.0162\n",
        "              output_skintone[0][0][2]*=0.5785\n",
        "              output_skintone[0][0][3]*=0.1693\n",
        "\n",
        "\n",
        "    predicted_skintone = np.argmax(output_skintone[0])\n",
        "    print(predicted_skintone)\n",
        "    predicted_skintone_label = skintone_mapping.get(predicted_skintone, 'Unknown')\n",
        "\n",
        "    df.at[index, 'skintone'] = predicted_skintone_label\n",
        "\n",
        "\n",
        "    completed_images += 1\n",
        "    progress_percentage = (completed_images / total_images) * 100\n",
        "\n",
        "    print(f\"Predicted race for {image_file}: {prediction_race_label}\")\n",
        "    print(f\"Progress: {progress_percentage:.2f}%\")\n",
        "\n",
        "df.to_excel(answer_path, index=False, engine='openpyxl')\n",
        "print(\"Process completed. Check the updated Excel file.\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "diJ_XM_TqBpz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
